---
title: "DataPreperation"
author: "Xavier"
date: "2023-11-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Rosenberg Scores 
##1.1. Creating a long dataset, with Rosenberg scores when available for each year. 
By running 1.1. + 1.2. + 1.3. + 1.4. you will get self_esteem_final, a long dataset with the values for the rosenberg score per year per participant.  

note: There was no personality survey in 2016

```{r}
# Initialize an empty dataframe to store the combined results
self_esteem <- data.frame()

# Define the suffixes for each year
suffixes <- c("2008" = "a", "2009" = "b", "2010" = "c", "2011" = "d", 
              "2012" = "e", "2013" = "f", "2014" = "g", "2015" = "h", 
              "2017" = "i", "2018" = "j", "2019" = "k", "2020" = "l", 
              "2021" = "m", "2022" = "n")

# Loop through the years 2008 to 2022, excluding 2016
for (year in setdiff(2008:2022, 2016)) {
    # Construct the file name based on the year
    file_name <- paste0("RawData/Personality/Personality_", year, ".dta")
    
    # Read the data
    personality_data <- read_dta(file_name)
    
    # Create a temporary dataframe for the year
    temp_df <- data.frame(
        nomem_encr = personality_data$nomem_encr,
        year = year
    )
    
    # Get the suffix for the year
    suffix <- suffixes[as.character(year)]
    
    # Calculate the Rosenberg score components
    temp_pos <- rowSums(personality_data[,paste0("cp", substr(year, 3, 4), suffix, c("070", "071", "073", "075", "076"))], na.rm = FALSE)
    temp_neg <- rowSums(8 - personality_data[,paste0("cp", substr(year, 3, 4), suffix, c("072", "074", "077", "078", "079"))], na.rm = FALSE)
    
    # Check for NA in either temp_pos or temp_neg and calculate Rosenberg score
    temp_df$rosenberg <- ifelse(is.na(temp_pos) | is.na(temp_neg), NA, temp_pos + temp_neg)
    
    # Combine the temporary dataframe with the main dataframe
    self_esteem <- rbind(self_esteem, temp_df)
}

#In 2016 there was no personality survey, so we will inpute an NA observation for the relevant ID's 

# Subset for individuals with observations in 2015
subset_2015 <- subset(self_esteem, year == 2015)

# Modify the year to 2016 and set Rosenberg to NA
subset_2015$year <- 2016
subset_2015$rosenberg <- NA

# Append this modified subset to the original dataframe
self_esteem <- rbind(self_esteem, subset_2015)

# Optionally, sort the dataframe again
self_esteem <- self_esteem[order(self_esteem$nomem_encr, self_esteem$year), ]

# View the final combined dataframe
View(self_esteem)
```

##1.2. Checking NA's
it's clear there are many NA's in 2010, 2012, 2015, 2018. But there are still some people that have made the test in those years. 
```{r}
aggregate(is.na(rosenberg) ~ year, data = self_esteem, FUN = sum)
hist(self_esteem$rosenberg[self_esteem$year==2015], breaks = 49)

#total number of ID's in data-set
length(unique(self_esteem$nomem_encr))
```

We also have random observations missing, if people did not respond to the survey
So if in between the first time they submitted the personality survey, and the last time there is an observation missing, we will create a new observation with Rosenberg = NA. 

```{r}
#Check if there are persons who miss internal datasets

# Unique identifiers
unique_ids <- unique(self_esteem$nomem_encr)

# Initialize a list to store individuals with internal missing years
individuals_with_internal_missing_years <- list()

# Loop through each individual
for (id in unique_ids) {
    # Extract the years present for the individual
    individual_years <- self_esteem$year[self_esteem$nomem_encr == id]
    
    # Find the first and last year
    first_year <- min(individual_years)
    last_year <- max(individual_years)

    # Generate the expected range of years for this individual
    expected_years <- first_year:last_year

    # Check for missing years within this range
    missing_years <- setdiff(expected_years, individual_years)
    
    # If there are internal missing years, add them to the list
    if (length(missing_years) > 0) {
        individuals_with_internal_missing_years[[as.character(id)]] <- missing_years
    }
}

# Check the result
individuals_with_internal_missing_years

# Loop through each individual with internal missing years
for (id in names(individuals_with_internal_missing_years)) {
    # Loop through each missing year for this individual
    for (year in individuals_with_internal_missing_years[[id]]) {
        # Create a new entry with the id, missing year, and NA for Rosenberg
        new_entry <- data.frame(nomem_encr = as.numeric(id), year = year, rosenberg = NA)

        # Append this new entry to the self_esteem dataframe
        self_esteem <- rbind(self_esteem, new_entry)
    }
}

# Optionally, sort the dataframe again
self_esteem <- self_esteem[order(self_esteem$nomem_encr, self_esteem$year), ]

remove(unique_ids, individuals_with_internal_missing_years,individual_years, first_year, last_year, expected_years, missing_years, id, year, new_entry)

```

Rechecking NA's 
```{r}
#count the number of NA-observations
aggregate(is.na(rosenberg) ~ year, data = self_esteem, FUN = sum)


library(dplyr)

# Count the number of non-NA observations for Rosenberg per year
self_esteem %>%
  group_by(year) %>%
  summarise(count = sum(!is.na(rosenberg)))

# in %
library(dplyr)

# Count the number of NA observations per year
na_count <- aggregate(is.na(rosenberg) ~ year, data = self_esteem, FUN = sum)
names(na_count)[2] <- "na_count"

# Count the total number of observations per year
total_count <- self_esteem %>%
  group_by(year) %>%
  summarise(total = n())

# Merge the two dataframes
merged_counts <- merge(na_count, total_count, by = "year")

# Calculate the percentage of NA observations
merged_counts$na_percentage <- (merged_counts$na_count / merged_counts$total) * 100

# View the result
print(merged_counts)
remove(na_count, total_count, merged_counts)

```


##1.3. Inputing Data

We will now create a new variable: rosenberg_inp 
- This variable is the same as rosenberg, unless rosenberg is NA 
- If not: it will be take the last available score for Rosenberg for missing values in the years after the first participation in the personality survey.
       - Last Observation Carried Forward Approach

```{r}
library(zoo)

# Assuming your dataframe is named self_esteem and has columns 'nomem_encr', 'year', and 'rosenberg'
self_esteem$rosenberg_inp <- with(self_esteem, ave(rosenberg, nomem_encr, FUN = function(x) na.locf(x, na.rm = FALSE)))

# View the updated dataframe
head(self_esteem)

```
Rechecking NA's 
Indeed much lower now, only if there are no previous data.
```{r}
# in %
library(dplyr)

# Count the number of NA observations per year
na_count <- aggregate(is.na(rosenberg_inp) ~ year, data = self_esteem, FUN = sum)
names(na_count)[2] <- "na_count"

# Count the total number of observations per year
total_count <- self_esteem %>%
  group_by(year) %>%
  summarise(total = n())

# Merge the two dataframes
merged_counts <- merge(na_count, total_count, by = "year")

# Calculate the percentage of NA observations
merged_counts$na_percentage <- (merged_counts$na_count / merged_counts$total) * 100

# View the result
print(merged_counts)
remove(na_count, total_count, merged_counts)

```

##1.4. Creating dummies
```{r}
#dummy, coded 0 as below or equal to 35 (low SE) or 1 as higher than 35
#or 0 if below or equal to 40 etc.
self_esteem$dum_35_inp <- ifelse(self_esteem$rosenberg_inp <= 35, 0, 1)
self_esteem$dum_40_inp <- ifelse(self_esteem$rosenberg_inp <= 40, 0, 1)
self_esteem$dum_45_inp <- ifelse(self_esteem$rosenberg_inp <= 45, 0, 1)


table(self_esteem$dum_35_inp)
proportions(table(self_esteem$dum_35_inp))

table(self_esteem$dum_40)
proportions(table(self_esteem$dum_40_inp))

table(self_esteem$dum_45)
proportions(table(self_esteem$dum_45_inp))
```


##1.5. Cleaning up and Saving Data
```{r} 

# Define the file path
file_path <- "ProcessedData/self_esteem_final.csv"

# Check if the ProcessedData folder exists, create it if it doesn't
if (!dir.exists("ProcessedData")) {
  dir.create("ProcessedData")
}

# Save the self_esteem dataframe as a CSV file
write.csv(self_esteem, file_path, row.names = FALSE)

# Print a message to confirm saving
print(paste("File saved as", file_path))

remove(temp_df, personality_data, file_name, suffix, suffixes, temp_neg, temp_pos, year, id, individuals, rosenberg_2015, row, rows_to_update, individual_avg, self_esteem_2016, individual_variation, file_path, subset_2015, individuals_with_missing_years, individuals_with_internal_missing_years)

```

#2. Lay-off Dummies
#2.1. Designing dummy for working vs. not working: 

Using criteria of Van der Meer & Wielers (2016): 

"We differentiate between employed and unemployed. The employment status is captured in 
the background variables of the study. Everyone in paid employment is employed, (belbezig = 1), everyone searching for a job is unemployed (belbezig = 4, 5 and 6). We do not have a reliable measure of the duration of unemployment. This is not asked in the questionnaire and is very difficult to construct. We can only see if respondents were unemployed in consecutive waves. We will miss a period of in between employment, but also a period of in between unemployment if one indicates to be employed in two consecutive waves."

empo: 
We also consider people working in the family business (belbezig = 2), and freelancers/independent contractors (belbezig = 3) as employed

For our survival analysis, considering we will be looking at lay-offs, we also include belbezig = 5 as 'employed', as these are first time job-seekers, since they have never been laid-of. The same for belbezig = 7 for 'students'

Unemployed
belbezig = 4, 6


Censoring: 
People that went with (early) retirement or lost their job due to a disablity are NA, and thus drop-out of the survival analysis. '

As we exclude people that are too young to have job, belbezig = 14.


Dummy = 1 if employed, 0 = if unemployed


```{r}
# Initialize an empty dataframe for the combined results
employment <- data.frame()

# Loop through each year from 2008 to 2022
for (year in 2008:2022) {
    # Construct the file name based on the year
    file_name <- paste0("RawData/Background Variables/bg_", year, ".dta")
    
    # Read the data
    bg_data <- read_dta(file_name)
    
    # Create the emp_status column
    # Employed (belbezig = 1, 2, 3), Unemployed (belbezig = 4, 5, 6)
    bg_data$emp_status <- ifelse(bg_data$belbezig %in% c(1, 2, 3, 5, 7), 1,   ifelse(bg_data$belbezig %in% c(4, 6), 0, NA))
    
    # Create a temporary dataframe for the year
    temp_df <- data.frame(
        id = bg_data$nomem_encr,
        emp_status = bg_data$emp_status,
        year = year
    )
    
    # Combine the temporary dataframe with the main dataframe
    employment <- rbind(employment, temp_df)
}

# View the final combined dataframe
View(employment)

```

## 2.2. Laid-off variable: 
A person is considered laid off (employment$laid_off = 1) if at t = 1, emp_status = 1, and at t = 2, emp_status = 0 '

```{r}
# Sort the employment dataframe by id and year
employment <- employment[order(employment$id, employment$year), ]

# Initialize the laid_off column with NA
employment$laid_off <- NA

# Loop through the dataframe to identify layoffs
for (i in 1:(nrow(employment) - 1)) {
    if (employment$id[i] == employment$id[i + 1]) {
        if (is.na(employment$emp_status[i]) || is.na(employment$emp_status[i + 1])) {
            employment$laid_off[i] <- NA
        } else if (employment$emp_status[i] == 1 && employment$emp_status[i + 1] == 0) {
            employment$laid_off[i] <- 1
        } else {
            employment$laid_off[i] <- 0
        }
    }
}

# View the updated dataframe
View(employment)
```

#2.3. Lay-offs, NA Corrected
The above variables creates many na's
so laid_off_na_corrected corrects if a person has a different job status (e.g. housewife, retirement etc)

If both are NA, lay-off = 0 
If t=0 is na, and t = 1 is 0 then lay-off = 1
If t=0 is na, and t = 1 is 1 then lay-off = 0
If t=0 is 1, and t=1 is NA then lay-off = 0
If t=0 is 0, and t=1 is NA then lay-off = 0

```{r}
# Sort the employment dataframe by id and year
employment <- employment[order(employment$id, employment$year), ]

# Initialize the laid_off_na_corrected column with 0
employment$laid_off_na_corrected <- 0

# Loop through the dataframe to set laid_off_na_corrected
for (i in 1:(nrow(employment) - 1)) {
    if (employment$id[i] == employment$id[i + 1]) {
        current_status <- employment$emp_status[i]
        next_status <- employment$emp_status[i + 1]

        # Check for NA in current and next status
        if (is.na(current_status) || is.na(next_status)) {
            if (is.na(current_status) && !is.na(next_status) && next_status == 0) {
                employment$laid_off_na_corrected[i] <- 1
            } else {
                employment$laid_off_na_corrected[i] <- 0
            }
        } else {
            # Apply conditions for non-NA values
            employment$laid_off_na_corrected[i] <- ifelse(current_status == 1 && next_status == 0, 1, 0)
        }
    }
}


```

##2.4. Save and clean 
```{r}
# Define the file path
file_path <- "ProcessedData/employment_final.csv"

# Check if the ProcessedData folder exists, create it if it doesn't
if (!dir.exists("ProcessedData")) {
  dir.create("ProcessedData")
}

# Save the self_esteem dataframe as a CSV file
write.csv(employment, file_path, row.names = FALSE)

# Print a message to confirm saving
print(paste("File saved as", file_path))

remove(bg_data, current_status, file_name, i, next_status, temp_df, year, file_path)
```

#3. Merge Employment and Self-Esteem 
#3.1. Merge Employment and Self-Esteem 

```{r}
library(dplyr)
self_esteem <- rename(self_esteem, id = nomem_encr )
```

```{r}
df_no_cov <- merge(employment, self_esteem, by = c("id", "year"), all = T)

# Count the number of observations where both Rosenberg and laid_off_na_corrected are available
both_available <- sum(!is.na(df_no_cov$rosenberg_inp) & !is.na(df_no_cov$laid_off_na_corrected))

# Count the number of observations where one of them is missing
one_missing <- sum(is.na(df_no_cov$rosenberg_inp) | is.na(df_no_cov$laid_off_na_corrected))

# Count the number of observations where rosenberg of them is missing
rosenberg_missing <- sum(is.na(df_no_cov$rosenberg_inp) & !is.na(df_no_cov$laid_off_na_corrected))

laid_off_missing <- sum(!is.na(df_no_cov$rosenberg_inp) & is.na(df_no_cov$laid_off_na_corrected))

# Print the results
cat("Number of observations with both values available:", both_available, "\n")
cat("Number of observations with one value missing:", one_missing, "\n")
cat("Number of observations with Rosenberg only missing:", rosenberg_missing, "\n")
cat("Number of observations with Laid-Off only missing:", laid_off_missing, "\n")

remove(both_available, one_missing, rosenberg_missing, laid_off_missing)
```

So especially the number of observations with Rosenberg only missing is very high. These supposedly 74.090 observations of people that have never participated in the personality survey. We will exclude them from the analysis. 

```{r}
df_no_cov <- subset(df_no_cov, !is.na(rosenberg_inp))

```

##3.3 Save data and clean

```{r}
# Define the file path
file_path <- "ProcessedData/df_no_cov_final.csv"

# Check if the ProcessedData folder exists, create it if it doesn't
if (!dir.exists("ProcessedData")) {
  dir.create("ProcessedData")
}

# Save the self_esteem dataframe as a CSV file
write.csv(df_no_cov, file_path, row.names = FALSE)

# Print a message to confirm saving
print(paste("File saved as", file_path))

remove(file_path)
```



