---
title: "DataPreperation"
author: "Xavier"
date: "2023-11-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Rosenberg Scores 
##1.1. Creating a long dataset, with Rosenberg scores when available for each year. 
By running 1.1. + 1.2. + 1.3. + 1.4. you will get self_esteem_final, a long dataset with the values for the rosenberg score per year per participant.  

note: There was no personality survey in 2016

```{r}
# Initialize an empty dataframe to store the combined results
self_esteem <- data.frame()

# Define the suffixes for each year
suffixes <- c("2008" = "a", "2009" = "b", "2010" = "c", "2011" = "d", 
              "2012" = "e", "2013" = "f", "2014" = "g", "2015" = "h", 
              "2017" = "i", "2018" = "j", "2019" = "k", "2020" = "l", 
              "2021" = "m", "2022" = "n")

# Loop through the years 2008 to 2022, excluding 2016
for (year in setdiff(2008:2022, 2016)) {
    # Construct the file name based on the year
    file_name <- paste0("RawData/Personality/Personality_", year, ".dta")
    
    # Read the data
    personality_data <- read_dta(file_name)
    
    # Create a temporary dataframe for the year
    temp_df <- data.frame(
        nomem_encr = personality_data$nomem_encr,
        year = year
    )
    
    # Get the suffix for the year
    suffix <- suffixes[as.character(year)]
    
    # Calculate the Rosenberg score components
    temp_pos <- rowSums(personality_data[,paste0("cp", substr(year, 3, 4), suffix, c("070", "071", "073", "075", "076"))], na.rm = FALSE)
    temp_neg <- rowSums(8 - personality_data[,paste0("cp", substr(year, 3, 4), suffix, c("072", "074", "077", "078", "079"))], na.rm = FALSE)
    
    # Check for NA in either temp_pos or temp_neg and calculate Rosenberg score
    temp_df$rosenberg <- ifelse(is.na(temp_pos) | is.na(temp_neg), NA, temp_pos + temp_neg)
    
    # Combine the temporary dataframe with the main dataframe
    self_esteem <- rbind(self_esteem, temp_df)
}

#In 2016 there was no personality survey, so we will inpute an NA observation for the relevant ID's 

# Subset for individuals with observations in 2015
subset_2015 <- subset(self_esteem, year == 2015)

# Modify the year to 2016 and set Rosenberg to NA
subset_2015$year <- 2016
subset_2015$rosenberg <- NA

# Append this modified subset to the original dataframe
self_esteem <- rbind(self_esteem, subset_2015)

# Optionally, sort the dataframe again
self_esteem <- self_esteem[order(self_esteem$nomem_encr, self_esteem$year), ]

# View the final combined dataframe
View(self_esteem)
```

##1.2. Checking NA's
it's clear there are many NA's in 2010, 2012, 2015, 2018. But there are still some people that have made the test in those years. 
```{r}
aggregate(is.na(rosenberg) ~ year, data = self_esteem, FUN = sum)
hist(self_esteem$rosenberg[self_esteem$year==2015], breaks = 49)

#total number of ID's in data-set
length(unique(self_esteem$nomem_encr))

#Number of ID's per year
```

We will now create a new variable: rosenberg_inp 
- This variable is the same as rosenberg, unless rosenberg is NA 
- If not: it will be take the last available score for Rosenberg for missing values in the years after the first participation in the personality survey 

This however will not take care of: 
1. Missing observations of years before the first participation in the personality survey
            Due to reversed causality, we cannot use future values in the imputation 
2. It will create Rosenberg scores, even if a person dropped out before that time. This will later have to be corrected. 










##1.5. Cleaning up and Saving Data
```{r} 

# Define the file path
file_path <- "ProcessedData/self_esteem_final.csv"

# Check if the ProcessedData folder exists, create it if it doesn't
if (!dir.exists("ProcessedData")) {
  dir.create("ProcessedData")
}

# Save the self_esteem dataframe as a CSV file
write.csv(self_esteem, file_path, row.names = FALSE)

# Print a message to confirm saving
print(paste("File saved as", file_path))

remove(temp_df, personality_data, file_name, suffix, suffixes, temp_neg, temp_pos, year, id, individuals, rosenberg_2015, row, rows_to_update, individual_avg, self_esteem_2016, individual_variation, file_path, subset_2015)

```

#2. Lay-off Dummies
#2.1. Designing dummy for working vs. not working: 

Using criteria of Van der Meer & Wielers (2016): 

"We differentiate between employed and unemployed. The employment status is captured in 
the background variables of the study. Everyone in paid employment is employed, (belbezig = 1), everyone searching for a job is unemployed (belbezig = 4, 5 and 6). We do not have a reliable measure of the duration of unemployment. This is not asked in the questionnaire and is very difficult to construct. We can only see if respondents were unemployed in consecutive waves. We will miss a period of in between employment, but also a period of in between unemployment if one indicates to be employed in two consecutive waves."

empo: 
We also consider people working in the family business (belbezig = 2), and freelancers/independent contractors (belbezig = 3) as employed

For our survival analysis, considering we will be looking at lay-offs, we also include belbezig = 5 as 'employed', as these are first time job-seekers, since they have never been laid-of. The same for belbezig = 7 for 'students'

Unemployed
belbezig = 4, 6


Censoring: 
People that went with (early) retirement or lost their job due to a disablity are NA, and thus drop-out of the survival analysis. '

As we exclude people that are too young to have job, belbezig = 14.


Dummy = 1 if employed, 0 = if unemployed


```{r}
# Initialize an empty dataframe for the combined results
employment <- data.frame()

# Loop through each year from 2008 to 2022
for (year in 2008:2022) {
    # Construct the file name based on the year
    file_name <- paste0("RawData/Background Variables/bg_", year, ".dta")
    
    # Read the data
    bg_data <- read_dta(file_name)
    
    # Create the emp_status column
    # Employed (belbezig = 1, 2, 3), Unemployed (belbezig = 4, 5, 6)
    bg_data$emp_status <- ifelse(bg_data$belbezig %in% c(1, 2, 3, 5, 7), 1,   ifelse(bg_data$belbezig %in% c(4, 6), 0, NA))
    
    # Create a temporary dataframe for the year
    temp_df <- data.frame(
        id = bg_data$nomem_encr,
        emp_status = bg_data$emp_status,
        year = year
    )
    
    # Combine the temporary dataframe with the main dataframe
    employment <- rbind(employment, temp_df)
}

# View the final combined dataframe
View(employment)

```

## 2.2. Laid-off variable: 
A person is considered laid off (employment$laid_off = 1) if at t = 1, emp_status = 1, and at t = 2, emp_status = 0 '

```{r}
# Sort the employment dataframe by id and year
employment <- employment[order(employment$id, employment$year), ]

# Initialize the laid_off column with NA
employment$laid_off <- NA

# Loop through the dataframe to identify layoffs
for (i in 1:(nrow(employment) - 1)) {
    if (employment$id[i] == employment$id[i + 1]) {
        if (is.na(employment$emp_status[i]) || is.na(employment$emp_status[i + 1])) {
            employment$laid_off[i] <- NA
        } else if (employment$emp_status[i] == 1 && employment$emp_status[i + 1] == 0) {
            employment$laid_off[i] <- 1
        } else {
            employment$laid_off[i] <- 0
        }
    }
}

# View the updated dataframe
View(employment)
```

#2.3. Lay-offs, NA Corrected
The above variables creates many na's
so laid_off_na_corrected corrects if a person has a different job status (e.g. housewife, retirement etc)

If both are NA, lay-off = 0 
If t=0 is na, and t = 1 is 0 then lay-off = 1
If t=0 is na, and t = 1 is 1 then lay-off = 0
If t=0 is 1, and t=1 is NA then lay-off = 0
If t=0 is 0, and t=1 is NA then lay-off = 0

```{r}
# Sort the employment dataframe by id and year
employment <- employment[order(employment$id, employment$year), ]

# Initialize the laid_off_na_corrected column with 0
employment$laid_off_na_corrected <- 0

# Loop through the dataframe to set laid_off_na_corrected
for (i in 1:(nrow(employment) - 1)) {
    if (employment$id[i] == employment$id[i + 1]) {
        current_status <- employment$emp_status[i]
        next_status <- employment$emp_status[i + 1]

        # Check for NA in current and next status
        if (is.na(current_status) || is.na(next_status)) {
            if (is.na(current_status) && !is.na(next_status) && next_status == 0) {
                employment$laid_off_na_corrected[i] <- 1
            } else {
                employment$laid_off_na_corrected[i] <- 0
            }
        } else {
            # Apply conditions for non-NA values
            employment$laid_off_na_corrected[i] <- ifelse(current_status == 1 && next_status == 0, 1, 0)
        }
    }
}


```

##2.4. Save and clean 
```{r}
# Define the file path
file_path <- "ProcessedData/employment_final.csv"

# Check if the ProcessedData folder exists, create it if it doesn't
if (!dir.exists("ProcessedData")) {
  dir.create("ProcessedData")
}

# Save the self_esteem dataframe as a CSV file
write.csv(employment, file_path, row.names = FALSE)

# Print a message to confirm saving
print(paste("File saved as", file_path))

remove(bg_data, current_status, file_name, i, next_status, temp_df, year, file_path)
```

#3. Merge Employment and Self-Esteem and Inpute Missing Data 
#3.1. Merge Employment and Self-Esteem 

```{r}
library(dplyr)
self_esteem <- rename(self_esteem, id = nomem_encr )
```

```{r}
df_no_cov <- merge(employment, self_esteem, by = c("id", "year"), all = T)

# Count the number of observations where both Rosenberg and laid_off_na_corrected are available
both_available <- sum(!is.na(df_no_cov$rosenberg) & !is.na(df_no_cov$laid_off_na_corrected))

# Count the number of observations where one of them is missing
one_missing <- sum(is.na(df_no_cov$rosenberg) | is.na(df_no_cov$laid_off_na_corrected))

# Print the results
cat("Number of observations with both values available:", both_available, "\n")
cat("Number of observations with one value missing:", one_missing, "\n")

```

Clearly, many respondents have not filled in the personality survey every year. 
When available, we will use the latest available score from Rosenberg as a substitute: 

##3.2. Inputing Rosenberg Scores
```{r}
for (i in 2:nrow(df_no_cov)) {
    # Check if the current row's rosenberg is NA
    if (is.na(df_no_cov$rosenberg[i])) {
        # Check if there are any previous non-NA rosenberg scores for this id
        previous_rosenberg <- df_no_cov$rosenberg[1:(i-1)][df_no_cov$id[1:(i-1)] == df_no_cov$id[i]]
        
        if (any(!is.na(previous_rosenberg))) {
            # Find the last known rosenberg score for this individual
            last_known_index <- max(which(df_no_cov$id[1:(i-1)] == df_no_cov$id[i] & !is.na(df_no_cov$rosenberg[1:(i-1)])))
            df_no_cov$rosenberg[i] <- df_no_cov$rosenberg[last_known_index]
        }
    }
}

# View the updated dataframe
View(df_no_cov)
```

