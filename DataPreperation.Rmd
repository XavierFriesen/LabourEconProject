---
title: "DataPreperation"
author: "Xavier en Cal"
date: "2023-11-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Rosenberg Scores 
##1.1. Creating a long dataset, with Rosenberg scores when available for each year. 
By running 1.1. + 1.2. + 1.3. + 1.4. you will get self_esteem_final, a long dataset with the values for the rosenberg score per year per participant.  

note: There was no personality survey in 2016

```{r}
library(haven)
# Initialize an empty dataframe to store the combined results
self_esteem <- data.frame()

# Define the suffixes for each year
suffixes <- c("2008" = "a", "2009" = "b", "2010" = "c", "2011" = "d", 
              "2012" = "e", "2013" = "f", "2014" = "g", "2015" = "h", 
              "2017" = "i", "2018" = "j", "2019" = "k", "2020" = "l", 
              "2021" = "m", "2022" = "n")

# Loop through the years 2008 to 2022, excluding 2016
for (year in setdiff(2008:2022, 2016)) {
    # Construct the file name based on the year
    file_name <- paste0("RawData/Personality/Personality_", year, ".dta")
    
    # Read the data
    personality_data <- read_dta(file_name)
    
    # Create a temporary dataframe for the year
    temp_df <- data.frame(
        nomem_encr = personality_data$nomem_encr,
        year = year
    )
    
    # Get the suffix for the year
    suffix <- suffixes[as.character(year)]
    
    # Calculate the Rosenberg score components
    temp_pos <- rowSums(personality_data[,paste0("cp", substr(year, 3, 4), suffix, c("070", "071", "073", "075", "076"))], na.rm = FALSE)
    temp_neg <- rowSums(8 - personality_data[,paste0("cp", substr(year, 3, 4), suffix, c("072", "074", "077", "078", "079"))], na.rm = FALSE)
    
    # Check for NA in either temp_pos or temp_neg and calculate Rosenberg score
    temp_df$rosenberg <- ifelse(is.na(temp_pos) | is.na(temp_neg), NA, temp_pos + temp_neg)
    
    # Combine the temporary dataframe with the main dataframe
    self_esteem <- rbind(self_esteem, temp_df)
}

#In 2016 there was no personality survey, so we will inpute an NA observation for the relevant ID's 

# Subset for individuals with observations in 2015
subset_2015 <- subset(self_esteem, year == 2015)

# Modify the year to 2016 and set Rosenberg to NA
subset_2015$year <- 2016
subset_2015$rosenberg <- NA

# Append this modified subset to the original dataframe
self_esteem <- rbind(self_esteem, subset_2015)

# Optionally, sort the dataframe again
self_esteem <- self_esteem[order(self_esteem$nomem_encr, self_esteem$year), ]

# View the final combined dataframe
View(self_esteem)
```

##1.2. Checking NA's
it's clear there are many NA's in 2010, 2012, 2015, 2018. But there are still some people that have made the test in those years. 
```{r}
aggregate(is.na(rosenberg) ~ year, data = self_esteem, FUN = sum)
hist(self_esteem$rosenberg[self_esteem$year==2015], breaks = 49)

#total number of ID's in data-set
length(unique(self_esteem$nomem_encr))
```

We also have random observations missing, if people did not respond to the survey
So if in between the first time they submitted the personality survey, and the last time there is an observation missing, we will create a new observation with Rosenberg = NA. 

```{r}
#Check if there are persons who miss internal data 

# Unique identifiers
unique_ids <- unique(self_esteem$nomem_encr)

# Initialize a list to store individuals with internal missing years
individuals_with_internal_missing_years <- list()

# Loop through each individual
for (id in unique_ids) {
    # Extract the years present for the individual
    individual_years <- self_esteem$year[self_esteem$nomem_encr == id]
    
    # Find the first and last year
    first_year <- min(individual_years)
    last_year <- max(individual_years)

    # Generate the expected range of years for this individual
    expected_years <- first_year:last_year

    # Check for missing years within this range
    missing_years <- setdiff(expected_years, individual_years)
    
    # If there are internal missing years, add them to the list
    if (length(missing_years) > 0) {
        individuals_with_internal_missing_years[[as.character(id)]] <- missing_years
    }
}

# Check the result
individuals_with_internal_missing_years

# Loop through each individual with internal missing years
for (id in names(individuals_with_internal_missing_years)) {
    # Loop through each missing year for this individual
    for (year in individuals_with_internal_missing_years[[id]]) {
        # Create a new entry with the id, missing year, and NA for Rosenberg
        new_entry <- data.frame(nomem_encr = as.numeric(id), year = year, rosenberg = NA)

        # Append this new entry to the self_esteem dataframe
        self_esteem <- rbind(self_esteem, new_entry)
    }
}

# Optionally, sort the dataframe again
self_esteem <- self_esteem[order(self_esteem$nomem_encr, self_esteem$year), ]

remove(unique_ids, individuals_with_internal_missing_years,individual_years, first_year, last_year, expected_years, missing_years, id, year, new_entry)

```

Rechecking NA's 
```{r}
#count the number of NA-observations
aggregate(is.na(rosenberg) ~ year, data = self_esteem, FUN = sum)
library(dplyr)

# Count the number of non-NA observations for Rosenberg per year
self_esteem %>%
  group_by(year) %>%
  summarise(count = sum(!is.na(rosenberg)))

# in %
library(dplyr)

# Count the number of NA observations per year
na_count <- aggregate(is.na(rosenberg) ~ year, data = self_esteem, FUN = sum)
names(na_count)[2] <- "na_count"

# Count the total number of observations per year
total_count <- self_esteem %>%
  group_by(year) %>%
  summarise(total = n())

# Merge the two dataframes
merged_counts <- merge(na_count, total_count, by = "year")

# Calculate the percentage of NA observations
merged_counts$na_percentage <- (merged_counts$na_count / merged_counts$total) * 100

# View the result
print(merged_counts)
remove(na_count, total_count, merged_counts)

```


##1.3. Inputing Data
We will now create a new variable: rosenberg_inp 
- This variable is the same as rosenberg, unless rosenberg is NA 
- If not: it will take the last available score for Rosenberg for missing values in the years after the first participation in the personality survey.
       - Last Observation Carried Forward Approach

```{r}
library(zoo)
self_esteem$rosenberg_inp <- with(self_esteem, ave(rosenberg, nomem_encr, FUN = function(x) na.locf(x, na.rm = FALSE)))

# View the updated dataframe
head(self_esteem)

```

Rechecking NA's 
```{r}
# in %
library(dplyr)

# Count the number of NA observations per year
na_count <- aggregate(is.na(rosenberg_inp) ~ year, data = self_esteem, FUN = sum)
names(na_count)[2] <- "na_count"

# Count the total number of observations per year
total_count <- self_esteem %>%
  group_by(year) %>%
  summarise(total = n())

# Merge the two dataframes
merged_counts <- merge(na_count, total_count, by = "year")

# Calculate the percentage of NA observations
merged_counts$na_percentage <- (merged_counts$na_count / merged_counts$total) * 100

# View the result
print(merged_counts)
remove(na_count, total_count, merged_counts)

```

Indeed much lower now, only if there is no previous data, for example because the Rosenberg Self-esteem scale was not submitted, but other parts of the personality survey were.

##1.4. Creating dummies
```{r}
#dummy, coded 0 as below or equal to 35 (low SE) or 1 as higher than 35
#or 0 if below or equal to 45 etc.
self_esteem$dum_20_inp <- ifelse(self_esteem$rosenberg_inp <= 20, 0, 1)
self_esteem$dum_25_inp <- ifelse(self_esteem$rosenberg_inp <= 25, 0, 1)
self_esteem$dum_35_inp <- ifelse(self_esteem$rosenberg_inp <= 35, 0, 1)
self_esteem$dum_40_inp <- ifelse(self_esteem$rosenberg_inp <= 40, 0, 1)
self_esteem$dum_45_inp <- ifelse(self_esteem$rosenberg_inp <= 45, 0, 1)

table(self_esteem$dum_35_inp)
proportions(table(self_esteem$dum_35_inp))

table(self_esteem$dum_40)
proportions(table(self_esteem$dum_40_inp))

table(self_esteem$dum_45)
proportions(table(self_esteem$dum_45_inp))
```


##1.5. Cleaning up and Saving Data
```{r} 
library(dplyr)
self_esteem <- rename(self_esteem, id = nomem_encr)

# Define the file path
file_path <- "ProcessedData/self_esteem_final.csv"

# Check if the ProcessedData folder exists, create it if it doesn't
if (!dir.exists("ProcessedData")) {
  dir.create("ProcessedData")
}

# Save the self_esteem dataframe as a CSV file
write.csv(self_esteem, file_path, row.names = FALSE)

# Print a message to confirm saving
print(paste("File saved as", file_path))

remove(temp_df, personality_data, file_name, suffix, suffixes, temp_neg, temp_pos,     file_path, subset_2015)

```

#2. Lay-off Dummies
##2.1. Designing dummy for working vs. not working: 

Using criteria of Van der Meer & Wielers (2016): 

"We differentiate between employed and unemployed. The employment status is captured in 
the background variables of the study. Everyone in paid employment is employed, (belbezig = 1), everyone searching for a job is unemployed (belbezig = 4, 5 and 6). We do not have a reliable measure of the duration of unemployment. This is not asked in the questionnaire and is very difficult to construct. We can only see if respondents were unemployed in consecutive waves. We will miss a period of in between employment, but also a period of in between unemployment if one indicates to be employed in two consecutive waves."

empo: 
We also consider people working in the family business (belbezig = 2), and freelancers/independent contractors (belbezig = 3), and students (belbezig = 7) as employed

Unemployed
belbezig = 4, 6

Censoring: 
People that went with (early) retirement or lost their job due to a disablity are NA, and thus drop-out of the survival analysis. For our survival analysis, considering we will be looking at lay-offs, we also code belbezig = 5 as NA, as these are first time job-seekers, and they have never been laid-off. We also exclude people that are too young to have job, belbezig = 14.

Dummy = 1 if employed, 0 = if unemployed


```{r}
# Initialize an empty dataframe for the combined results
employment <- data.frame()

# Loop through each year from 2008 to 2022
for (year in 2008:2022) {
    # Construct the file name based on the year
    file_name <- paste0("RawData/Background Variables/bg_", year, ".dta")
    
    # Read the data
    bg_data <- read_dta(file_name)
    
    # Create the emp_status column
    # Employed (belbezig = 1, 2, 3, 7), Unemployed (belbezig = 4, 6)
    bg_data$emp_status <- ifelse(bg_data$belbezig %in% c(1, 2, 3, 7), 1,   ifelse(bg_data$belbezig %in% c(4, 6), 0, NA))
    
    # Create a temporary dataframe for the year
    temp_df <- data.frame(
        id = bg_data$nomem_encr,
        emp_status = bg_data$emp_status,
        year = year
    )
    
    # Combine the temporary dataframe with the main dataframe
    employment <- rbind(employment, temp_df)
}

# View the final combined dataframe
View(employment)

```

## 2.2. Laid-off variable: 
A person is considered laid off at t=1 (employment$laid_off = 1) if at t = 1, emp_status = 1, and at t = 2, emp_status = 0 '

```{r}
# Sort the employment dataframe by id and year
employment <- employment[order(employment$id, employment$year), ]

# Initialize the laid_off column with NA
employment$laid_off <- NA

# Loop through the dataframe to identify layoffs
for (i in 1:(nrow(employment) - 1)) {
    if (employment$id[i] == employment$id[i + 1]) {
        if (is.na(employment$emp_status[i]) || is.na(employment$emp_status[i + 1])) {
            employment$laid_off[i] <- NA
        } else if (employment$emp_status[i] == 1 && employment$emp_status[i + 1] == 0) {
            employment$laid_off[i] <- 1
        } else {
            employment$laid_off[i] <- 0
        }
    }
}

# View the updated dataframe
View(employment)
```



##2.3. Save and clean 
```{r}
# Define the file path
file_path <- "ProcessedData/employment_final.csv"

# Check if the ProcessedData folder exists, create it if it doesn't
if (!dir.exists("ProcessedData")) {
  dir.create("ProcessedData")
}

# Save the self_esteem dataframe as a CSV file
write.csv(employment, file_path, row.names = FALSE)

# Print a message to confirm saving
print(paste("File saved as", file_path))

remove(bg_data, file_name, i, temp_df, year, file_path)
```

#3. Gathering Control Variables
##3.1. From background survey
Be careful, to avoid an error, all variables have to be converted. 
And this means that if the orig
```{r}
library(haven)
# Define the control variables
control_variables <- c("geslacht", "leeftijd", "partner", "brutoink_f", "oplmet",  "aantalki")

# Initialize an empty dataframe for the combined results
control_data_bg <- data.frame()

# Initialize an empty dataframe for the combined results
for (year in 2008:2022) {
    file_name <- paste0("RawData/Background Variables/bg_", year, ".dta")
    bg_data <- read_dta(file_name)

    # Directly convert labelled variables to numeric
    bg_data <- bg_data %>%
        mutate(across(all_of(control_variables), ~ifelse(is.na(.), NA, as.numeric(.))))

    temp_df <- bg_data[, c("nomem_encr", control_variables)]
    temp_df$year <- year

    control_data_bg <- rbind(control_data_bg, temp_df)
}

remove(temp_df, bg_data, file_name, control_variables, labelled_vars, year)

```
##3.2. Checking background control variables for outliers and creating dummies
```{r}
#remove all rows if nomenc = NA
control_data_bg <- control_data_bg[!is.na(control_data_bg$nomem_encr), ]

#rename
control_data_bg <- rename(control_data_bg, id = nomem_encr)

#gender
sum(is.na(control_data_bg$geslacht)) #1
table(control_data_bg$geslacht) #3 is other, but is only introduced since 2022, so we will have to exclude this from the analysis: 

#create dummy (female = 1, male = 0)
control_data_bg$female <- ifelse(control_data_bg$geslacht == 2, 1, ifelse(control_data_bg$geslacht == 1, 0, NA))

control_data_bg = subset(control_data_bg, select = -geslacht) #remove redundant variable

#age
sum(is.na(control_data_bg$leeftijd)) #0
hist(control_data_bg$leeftijd, breaks = 100) 
sum(control_data_bg$leeftijd < 16) #27096 observations under 16, while that is the minimum age to participate in the survey. These are household members of which parents participate, we will exclude them from the analysis, also since they are to young to work 
control_data_bg <- control_data_bg[control_data_bg$leeftijd > 15, ]

#CBS uses 74 years old as the maximum age for labour participation calculations. So we will exclude anybody from 75 years or older from the sample -> remember respondents that have stopped working earlier than 74 are already excluded from the laid-off variable 
sum(control_data_bg$leeftijd > 74) #9334
control_data_bg <- control_data_bg[control_data_bg$leeftijd < 75, ]

#partner 
sum(is.na(control_data_bg$partner)) #only 1
table(control_data_bg$partner) #no further transformations needed

#bruto_ink inputed
sum(is.na(control_data_bg$brutoink_f)) #9010, so be careful 
hist(control_data_bg$brutoink_f) #many zero's but no extreme outliers
sum(control_data_bg$brutoink_f > 4000, na.rm = T) #14119
sum(control_data_bg$brutoink_f > 20000, na.rm = T) #140 

# Sorting brutoink_f in descending order and selecting the top 50 values
top_50_brutoink_f <- sort(control_data_bg$brutoink_f, decreasing = TRUE)[1:50]

# Viewing the top 50 values
top_50_brutoink_f #the top 10 values are clearly higher than the rest, and especially 1662336 is repeated 7 times, the biggest seems to be a typo. We will remove the top 10 biggest values for brutoink_f 

control_data_bg <- control_data_bg[control_data_bg$brutoink_f < 552001, ]
remove(top_50_brutoink_f)

#Number of Children
sum(is.na(control_data_bg$aantalki)) #0 
hist(control_data_bg$aantalki)

#creating dummy (1= if 1 or more dependent children, 0 = if no depending children): 
control_data_bg$d.children <- ifelse(control_data_bg$aantalki > 0, 1, 0)
table(control_data_bg$d.children)

#Education Attained 
sum(is.na(control_data_bg$oplmet)) #1
table(control_data_bg$oplmet)

#We will include #7 other, #8 (not yet completed any education) and #9 (not yet started any education) in 1 as primary school or less, also since options 8 and 9 are no longer available since december 2008)

control_data_bg$oplmet[control_data_bg$oplmet==7] = 1
control_data_bg$oplmet[control_data_bg$oplmet==8] = 1
control_data_bg$oplmet[control_data_bg$oplmet==9] = 1
table(control_data_bg$oplmet) #succesful 

control_data_bg$oplmet <- as.factor(control_data_bg$oplmet) #as factor variable

#Paper uses high education dummy: we assume HBO (5) or WO (6)is high education = 1
control_data_bg$d.high_edu <- ifelse(control_data_bg$oplmet == 5, 1, ifelse(control_data_bg$oplmet == 6, 1, 0))

```

##3.3. From Schooling and Working Survey
We want to get 3 variables: 
cw*o133 How satisfied are you with your current work?
cw*o402 [In what sector do you work? / In what sector did you work in your last job
cw*o404 [What is your current profession? / What profession did you exercise in your last job?]


```{r}
# Mapping years to suffixes
year_suffixes <- setNames(
  paste0(
    formatC(8:22, width = 2, flag = "0"), 
    letters[1:15]
  ), 
  2008:2022
)

library(dplyr)
library(haven)

# Initialize an empty dataframe for the combined results
combined_job_data <- data.frame()

# Loop through each year from 2008 to 2022
for (year in 2008:2022) {
    # Construct the file name based on the year
    file_name <- paste0("RawData/Job/Job_", year, ".dta")

    # Read the data
    job_data <- read_dta(file_name)

    # Get the corresponding suffix for the year
    suffix <- year_suffixes[as.character(year)]

    # Construct the variable names based on the year and suffix
    var_names <- paste0("cw", suffix, c("133", "402", "404"))

    # Select and rename the variables
    selected_data <- job_data %>%
        select(nomem_encr, all_of(var_names)) %>%
        rename(cw133 = var_names[1], cw402 = var_names[2], cw404 = var_names[3])

    # Add the year column
    selected_data$year <- year

    # Combine with the main dataframe
    combined_job_data <- rbind(combined_job_data, selected_data)
}

# View the combined dataframe
View(combined_job_data)

remove(selected_data, var_names, suffix, file_name, job_data, year_suffixes)



```


##3.4. Checking control job variables 
```{r}
#remove all rows if nomenc = NA
combined_job_data <- combined_job_data[!is.na(combined_job_data$nomem_encr), ]

#job satisfaction 
table(combined_job_data$cw133)
#999 is equal to I don't know -> so will change to NA 
combined_job_data$cw133[combined_job_data$cw133 == 999] <- NA
sum(is.na(combined_job_data$cw133)) #40.000 so very high number of missing data,could partly be because of not working. 

#sector working 
table(combined_job_data$cw402)
sum(is.na(combined_job_data$cw402)) #31.000 might be because of people not working

#category 2 is really small (44), so we will combine them with category 3 industrial production. 
combined_job_data$cw402[combined_job_data$cw402 == 2] <- 3

#and now we make it a factor, to create dummy variables. 
combined_job_data$cw402 <- as.factor(combined_job_data$cw402)

#job_type
sum(is.na(combined_job_data$cw404)) #much lower, only 6000 missing variables
table(combined_job_data$cw404) #observations are nicely distributed, so no further transformation necessary
combined_job_data$cw404 <- as.factor(combined_job_data$cw404)

#rename variables 
combined_job_data <- rename(combined_job_data, id = nomem_encr, job_satisf = cw133, sector = cw402, job_type = cw404)

```

##3.5. Loading Health Variables 

```{r}
library(dplyr)
library(haven)

library(dplyr)
library(haven)

# Initialize an empty dataframe for the combined results
health <- data.frame()

# Define a vector with the years, excluding 2014
years <- setdiff(2008:2022, 2014)

# Loop through each year
for (year in years) {
    # Construct the file name based on the year
    file_name <- paste0("RawData/Health/Health_", year, ".dta")

    # Read the data
    health_data <- read_dta(file_name)

    # Construct the variable names based on the year
    # Starting with 'b' for 2008, incrementing each year, and skipping 'i' for 2014
    suffix_letter <- letters[(year - 2008) + 2 - ifelse(year > 2014, 1, 0)]
    year_suffix <- paste0(formatC(year - 2000, width = 2, flag = "0"), suffix_letter)  # e.g., "08b" for 2008

    var_names <- paste0("ch", year_suffix, c("014", "011", "133", "022"))

    # Select and rename the variables
    selected_data <- health_data %>%
        select(nomem_encr, all_of(var_names)) %>%
        rename(depressed = var_names[1], anxious = var_names[2], alcohol_consumption = var_names[3], health_hindrance = var_names[4])

    # Add the year column
    selected_data$year <- year

    # Combine with the main dataframe
    health <- rbind(health, selected_data)
}

rm(file_name, year_suffix, var_names, selected_data, health_data)

# View the combined dataframe
View(health)
```


##3.6. Editing Health Variable and Creating Dummies: 
Remember, there is no health data for 2014, we will correct for that after calculatign the dummies. 

```{r}
#creating dummy for health problems due to mental health: 1 if either ch07a011 (anxiety) is 4 or higher (often or more) or if ch*014 (depression) is 4 or higher (often or more)
sum(is.na(health$depressed))  #127
sum(is.na(health$anxious))   #127
table(health$depressed)
table(health$anxious)

health$d.mental_health <- ifelse(health$depressed > 3, 1, ifelse(health$anxious > 3, 1, 0))
table(health$d.mental_health)

#creating dummy for heavy alcohol consumption
sum(is.na(health$alcohol_consumption)) #249 
table(health$alcohol_consumption)

#1 if 1 or 2 (drinking five or more times a week), #0 othrewise
health$d.heavy_alcohol <- ifelse(health$alcohol_consumption < 3, 1, 0)
table(health$d.heavy_alcohol)

#creating dummy for general health hindrance
sum(is.na(health$health_hindrance))
table(health$health_hindrance)

#1 if 4 or 5 (4 quite a lot, 5 very much) 0 otherwise
health$job_hindrance <- ifelse(health$health_hindrance > 3, 1, 0)
table(health$job_hindrance)

health <- health %>% rename(id = nomem_encr) %>% select(-alcohol_consumption, -depressed, -anxious, -health_hindrance)

```
There was no survey in 2014, thus, these variables are systemetically missing. 
We will be using a last observation carried forward approach for all participants who already participated in 2013 to inpute values for that year. 

```{r}
library(dplyr)
library(zoo)

# Ensuring the health dataframe is sorted by id and year
health <- health %>% arrange(id, year)

# Carrying forward the last observation for each individual
health <- health %>% 
  group_by(id) %>% 
  mutate(
    d.mental_health = na.locf(d.mental_health, na.rm = FALSE),
    d.heavy_alcohol = na.locf(d.heavy_alcohol, na.rm = FALSE),
    job_hindrance = na.locf(job_hindrance, na.rm = FALSE)
  ) %>%
  ungroup()

# Create new 2014 records for individuals with data up to 2013
ids_with_2013 <- health %>% filter(year == 2013) %>% pull(id) %>% unique()

new_2014_records <- health %>% 
  filter(id %in% ids_with_2013, year == 2013) %>% 
  mutate(year = 2014)

# Append the new 2014 records to the health dataframe
health <- rbind(health, new_2014_records)

# Check the result
table(health$year)

remove(ids_with_2013, new_2014_records)

```


#4. Matching Covariates and Other Data 
##4.1. Merge Employment, Self-Esteem and Control-Variables 

```{r}
df_with_na <- merge(employment, self_esteem, by = c("id", "year"), all = TRUE)
df_with_na <- merge(df_with_na, control_data_bg, by = c("id", "year"), all = TRUE)
df_with_na <- merge(df_with_na, combined_job_data, by = c('id', "year"), all = TRUE)
df_with_na <- merge(df_with_na, health, by = c('id', "year"), all = TRUE)

```

##4.2. Dealing with NA's in data-set
We have a large number of missing values for all three datasets, 
First of all: rosenberg_inp and laid_off are critical: 
```{r}
# Count the number of observations where both Rosenberg and laid_off are available
both_available <- sum(!is.na(df_with_na$rosenberg_inp) & !is.na(df_with_na$laid_off))

# Count the number of observations where one of them is missing
one_missing <- sum(is.na(df_with_na$rosenberg_inp) | is.na(df_with_na$laid_off))

# Count the number of observations where rosenberg of them is missing
rosenberg_missing <- sum(is.na(df_with_na$rosenberg_inp) & !is.na(df_with_na$laid_off))

laid_off_missing <- sum(!is.na(df_with_na$rosenberg_inp) & is.na(df_with_na$laid_off))

# Print the results
cat("Number of observations with both values available:", both_available, "\n")
cat("Number of observations with one value missing:", one_missing, "\n")
cat("Number of observations with Rosenberg only missing:", rosenberg_missing, "\n")
cat("Number of observations with Laid-Off only missing:", laid_off_missing, "\n")
remove(both_available, one_missing, rosenberg_missing, laid_off_missing)
```

We have a lot of observations missing: 
- 41.022 people without Rosenberg_Inp, so people who have never participated in the personality survey 

- 42.170 observations with Laid-Off missing, meaning they were not available to work during the year of the survey or the year after (for example retired, disabled, working in the household)

We will only include observations with both observations available. 
We should later check for sensitivity of these results (A quick check: % of lay-offs is much lower in the excluded group, but this is not illogical, since a large part of this excluded group is not-working, thus cannot be laid-off)

```{r}
df_no_na <- subset(df_with_na, !is.na(rosenberg_inp)&!is.na(laid_off))
```

We should still check if there is a difference between the group who have filled in the personality survey, and those who haven't.

Notably: proportion of lay-offs is much higher in those that have filled out the personality survey. 
Potential attrition problem (???), further research is required

```{r}
table(df_with_na$laid_off[is.na(df_with_na$rosenberg_inp) == T])
table(df_with_na$laid_off[is.na(df_with_na$rosenberg_inp) == F])
```
##4.3. Creating factor variable based on which data is available for use of attrition analysis

if 1 = only data on rosenberg_inp and lay-off
if 2 = 1 + 


##4.3 Add time variable for survival analysis
time is 0 for the first year a person responds to the survey and increments by 1 for each subsequent year

```{r}
df_no_na <- df_no_na[order(df_no_na$id, df_no_na$year), ]

# Create the time variable
df_no_na <- transform(df_no_na, time = year - ave(year, id, FUN = min))

df_with_na <- df_with_na[order(df_with_na$id, df_with_na$year), ]

# Create the time variable
df_with_na <- transform(df_with_na, time = year - ave(year, id, FUN = min))

#creating factor variable for Rosenberg 
df_no_na$rosenberg_factor <- cut(df_no_na$rosenberg_inp, 
                                      breaks = c(10, 20, 30, 40, 55, 60, 70),   include.lowest = TRUE, labels = c("10-20", "21-30", "31-40", "41-50", "51-60", "61-70"))

df_no_na$rosenberg_factor<- relevel(df_no_na$rosenberg_factor, ref = "61-70")

# Check the new variable
table(df_no_na$rosenberg_factor)
```

##4.4. Checking missing covariates: 
6.12% of observations miss the background survey data. 
What's the reason there? 

```{r}
library(dplyr)

# Calculating the proportion of NAs for each variable
na_proportions <- df_no_na %>%
  summarise_all(~mean(is.na(.)))

# Viewing the results
na_proportions
remove(na_proportions)
```
##4.5 Splitting Male and Female Data-Set 
```{r}
df_no_na_fem <- subset(df_no_na, female ==1)
df_no_na_male <- subset(df_no_na, female ==0)
```


##4.5 Save data and clean
```{r}
# Define the file path
file_path <- "ProcessedData/df_no_na_final.csv"

# Check if the ProcessedData folder exists, create it if it doesn't
if (!dir.exists("ProcessedData")) {
  dir.create("ProcessedData")
}

# Save the self_esteem dataframe as a CSV file
write.csv(df_no_na, file_path, row.names = FALSE)

# Print a message to confirm saving
print(paste("File saved as", file_path))

remove(file_path)

file_path <- "ProcessedData/df_with_na_final.csv"

# Check if the ProcessedData folder exists, create it if it doesn't
if (!dir.exists("ProcessedData")) {
  dir.create("ProcessedData")
}

# Save the self_esteem dataframe as a CSV file
write.csv(df_with_na, file_path, row.names = FALSE)

# Print a message to confirm saving
print(paste("File saved as", file_path))

remove(file_path)

```
